# CMAKE generated file: DO NOT EDIT!
# Generated by "Unix Makefiles" Generator, CMake Version 3.31

# Delete rule output on recipe failure.
.DELETE_ON_ERROR:

#=============================================================================
# Special targets provided by cmake.

# Disable implicit rules so canonical targets will work.
.SUFFIXES:

# Disable VCS-based implicit rules.
% : %,v

# Disable VCS-based implicit rules.
% : RCS/%

# Disable VCS-based implicit rules.
% : RCS/%,v

# Disable VCS-based implicit rules.
% : SCCS/s.%

# Disable VCS-based implicit rules.
% : s.%

.SUFFIXES: .hpux_make_needs_suffix_list

# Command-line flag to silence nested $(MAKE).
$(VERBOSE)MAKESILENT = -s

#Suppress display of executed commands.
$(VERBOSE).SILENT:

# A target that is always out of date.
cmake_force:
.PHONY : cmake_force

#=============================================================================
# Set environment variables for the build.

# The shell in which to execute make rules.
SHELL = /bin/sh

# The CMake executable.
CMAKE_COMMAND = /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake

# The command to remove a file.
RM = /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E rm -f

# Escaping for special characters.
EQUALS = =

# The top-level source directory on which CMake was run.
CMAKE_SOURCE_DIR = /content/llama.cpp

# The top-level build directory on which CMake was run.
CMAKE_BINARY_DIR = /content/llama.cpp/build

# Include any dependencies generated for this target.
include examples/server/CMakeFiles/llama-server.dir/depend.make
# Include any dependencies generated by the compiler for this target.
include examples/server/CMakeFiles/llama-server.dir/compiler_depend.make

# Include the progress variables for this target.
include examples/server/CMakeFiles/llama-server.dir/progress.make

# Include the compile flags for this target's objects.
include examples/server/CMakeFiles/llama-server.dir/flags.make

examples/server/index.html.gz.hpp: /content/llama.cpp/examples/server/public/index.html.gz
	@$(CMAKE_COMMAND) -E cmake_echo_color "--switch=$(COLOR)" --blue --bold --progress-dir=/content/llama.cpp/build/CMakeFiles --progress-num=$(CMAKE_PROGRESS_1) "Generating index.html.gz.hpp"
	cd /content/llama.cpp/build/examples/server && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -DINPUT=/content/llama.cpp/examples/server/public/index.html.gz -DOUTPUT=/content/llama.cpp/build/examples/server/index.html.gz.hpp -P /content/llama.cpp/scripts/xxd.cmake

examples/server/loading.html.hpp: /content/llama.cpp/examples/server/public/loading.html
	@$(CMAKE_COMMAND) -E cmake_echo_color "--switch=$(COLOR)" --blue --bold --progress-dir=/content/llama.cpp/build/CMakeFiles --progress-num=$(CMAKE_PROGRESS_2) "Generating loading.html.hpp"
	cd /content/llama.cpp/build/examples/server && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -DINPUT=/content/llama.cpp/examples/server/public/loading.html -DOUTPUT=/content/llama.cpp/build/examples/server/loading.html.hpp -P /content/llama.cpp/scripts/xxd.cmake

examples/server/CMakeFiles/llama-server.dir/codegen:
.PHONY : examples/server/CMakeFiles/llama-server.dir/codegen

examples/server/CMakeFiles/llama-server.dir/server.cpp.o: examples/server/CMakeFiles/llama-server.dir/flags.make
examples/server/CMakeFiles/llama-server.dir/server.cpp.o: /content/llama.cpp/examples/server/server.cpp
examples/server/CMakeFiles/llama-server.dir/server.cpp.o: examples/server/CMakeFiles/llama-server.dir/compiler_depend.ts
	@$(CMAKE_COMMAND) -E cmake_echo_color "--switch=$(COLOR)" --green --progress-dir=/content/llama.cpp/build/CMakeFiles --progress-num=$(CMAKE_PROGRESS_3) "Building CXX object examples/server/CMakeFiles/llama-server.dir/server.cpp.o"
	cd /content/llama.cpp/build/examples/server && /usr/bin/c++ $(CXX_DEFINES) $(CXX_INCLUDES) $(CXX_FLAGS) -MD -MT examples/server/CMakeFiles/llama-server.dir/server.cpp.o -MF CMakeFiles/llama-server.dir/server.cpp.o.d -o CMakeFiles/llama-server.dir/server.cpp.o -c /content/llama.cpp/examples/server/server.cpp

examples/server/CMakeFiles/llama-server.dir/server.cpp.i: cmake_force
	@$(CMAKE_COMMAND) -E cmake_echo_color "--switch=$(COLOR)" --green "Preprocessing CXX source to CMakeFiles/llama-server.dir/server.cpp.i"
	cd /content/llama.cpp/build/examples/server && /usr/bin/c++ $(CXX_DEFINES) $(CXX_INCLUDES) $(CXX_FLAGS) -E /content/llama.cpp/examples/server/server.cpp > CMakeFiles/llama-server.dir/server.cpp.i

examples/server/CMakeFiles/llama-server.dir/server.cpp.s: cmake_force
	@$(CMAKE_COMMAND) -E cmake_echo_color "--switch=$(COLOR)" --green "Compiling CXX source to assembly CMakeFiles/llama-server.dir/server.cpp.s"
	cd /content/llama.cpp/build/examples/server && /usr/bin/c++ $(CXX_DEFINES) $(CXX_INCLUDES) $(CXX_FLAGS) -S /content/llama.cpp/examples/server/server.cpp -o CMakeFiles/llama-server.dir/server.cpp.s

# Object files for target llama-server
llama__server_OBJECTS = \
"CMakeFiles/llama-server.dir/server.cpp.o"

# External object files for target llama-server
llama__server_EXTERNAL_OBJECTS =

bin/llama-server: examples/server/CMakeFiles/llama-server.dir/server.cpp.o
bin/llama-server: examples/server/CMakeFiles/llama-server.dir/build.make
bin/llama-server: common/libcommon.a
bin/llama-server: src/libllama.so
bin/llama-server: ggml/src/libggml.so
bin/llama-server: ggml/src/libggml-cpu.so
bin/llama-server: ggml/src/ggml-cuda/libggml-cuda.so
bin/llama-server: ggml/src/libggml-base.so
bin/llama-server: /usr/local/cuda/targets/x86_64-linux/lib/stubs/libcuda.so
bin/llama-server: examples/server/CMakeFiles/llama-server.dir/link.txt
	@$(CMAKE_COMMAND) -E cmake_echo_color "--switch=$(COLOR)" --green --bold --progress-dir=/content/llama.cpp/build/CMakeFiles --progress-num=$(CMAKE_PROGRESS_4) "Linking CXX executable ../../bin/llama-server"
	cd /content/llama.cpp/build/examples/server && $(CMAKE_COMMAND) -E cmake_link_script CMakeFiles/llama-server.dir/link.txt --verbose=$(VERBOSE)

# Rule to build all files generated by this target.
examples/server/CMakeFiles/llama-server.dir/build: bin/llama-server
.PHONY : examples/server/CMakeFiles/llama-server.dir/build

examples/server/CMakeFiles/llama-server.dir/clean:
	cd /content/llama.cpp/build/examples/server && $(CMAKE_COMMAND) -P CMakeFiles/llama-server.dir/cmake_clean.cmake
.PHONY : examples/server/CMakeFiles/llama-server.dir/clean

examples/server/CMakeFiles/llama-server.dir/depend: examples/server/index.html.gz.hpp
examples/server/CMakeFiles/llama-server.dir/depend: examples/server/loading.html.hpp
	cd /content/llama.cpp/build && $(CMAKE_COMMAND) -E cmake_depends "Unix Makefiles" /content/llama.cpp /content/llama.cpp/examples/server /content/llama.cpp/build /content/llama.cpp/build/examples/server /content/llama.cpp/build/examples/server/CMakeFiles/llama-server.dir/DependInfo.cmake "--color=$(COLOR)"
.PHONY : examples/server/CMakeFiles/llama-server.dir/depend

